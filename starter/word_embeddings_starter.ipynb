{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2d650af",
   "metadata": {},
   "source": [
    "# AIG 230 — Week 4 Lab Notebook  \n",
    "## Word Embeddings: Learning Meaning from Context\n",
    "\n",
    "**Goal of this lab:** learn how *continuous vector representations* (embeddings) are learned from data, and how they are used in practical NLP workflows.\n",
    "\n",
    "### Learning objectives\n",
    "By the end of this lab, you should be able to:\n",
    "1. Explain **distributional semantics** (\"meaning from context\").\n",
    "2. Train word embeddings using **Word2Vec** and **FastText** (with Gensim).\n",
    "3. Use embeddings for **similarity search** and **analogy / vector algebra**.\n",
    "4. Visualize a word embedding space and interpret what you see.\n",
    "5. Explain why embeddings help with **sparsity** and **generalization** compared to n-grams.\n",
    "\n",
    "### Industry relevance (why you should care)\n",
    "Even in the era of transformers, embeddings remain widely used for:\n",
    "- **Semantic search** and query expansion  \n",
    "- **Similarity / recommendation** (nearest neighbors in vector space)  \n",
    "- **Clustering** and exploratory analysis  \n",
    "- Lightweight NLP systems where large models are too expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c01854",
   "metadata": {},
   "source": [
    "---\n",
    "## Checkpoint 0 (Before you code)\n",
    "In 2 to 4 sentences, answer:\n",
    "\n",
    "1. What is the main limitation of **one-hot vectors**?\n",
    "2. What does the phrase **\"meaning emerges from co-occurrence patterns\"** mean to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8699dadb",
   "metadata": {},
   "source": [
    "1. The main limitation of one-hot vectors is Sparsity and ir treat every word as equally unrelated.\n",
    "\n",
    "2. Meaning emerges from co-occurrence patterns means words used in similar contexts end up with similar vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde51e3c",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 0 — Setup\n",
    "\n",
    "We will use:\n",
    "- **scikit-learn** to load a real dataset (20 Newsgroups)\n",
    "- **NLTK** for basic tokenization and stopword removal\n",
    "- **Gensim** to train Word2Vec and FastText models\n",
    "- **matplotlib** for visualization\n",
    "\n",
    "> Tip: If you are running this notebook in Colab, the `pip install` cell below is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a823e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (run once)\n",
    "!pip -q install gensim scikit-learn nltk matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e3f7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1856c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ajays\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ajays\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources (run once per environment)\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f0d75d",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1 — Data: A real-world corpus\n",
    "\n",
    "We will train embeddings on the **20 Newsgroups** dataset.  \n",
    "This dataset contains posts from 20 topics (e.g., computers, sports, politics).\n",
    "\n",
    "Why this dataset is useful for embeddings:\n",
    "- It's real text (messy, varied vocabulary)\n",
    "- It contains many topic clusters, which embeddings can capture\n",
    "- It is large enough to learn meaningful co-occurrence patterns\n",
    "\n",
    "\n",
    "https://www.kaggle.com/datasets/crawford/20-newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68559f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 11314\n",
      "\n",
      "Example document snippet:\n",
      "\n",
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load the dataset\n",
    "# Use fetch_20newsgroups with subset=\"train\" and remove=(\"headers\", \"footers\", \"quotes\")\n",
    "# Store the data in a variable called 'data' and documents in 'documents'\n",
    "\n",
    "data = fetch_20newsgroups(subset=\"train\", remove=(\"headers\", \"footers\", \"quotes\"))  # YOUR CODE HERE\n",
    "documents = data.data  # YOUR CODE HERE\n",
    "\n",
    "print(\"Number of documents:\", len(documents))\n",
    "print(\"\\nExample document snippet:\\n\")\n",
    "print(documents[0][:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a8efa",
   "metadata": {},
   "source": [
    "### Preprocessing matters\n",
    "\n",
    "Embeddings learn from the text you provide. If you remove tokens, they cannot contribute to meaning.\n",
    "\n",
    "We will do *light preprocessing*:\n",
    "- lowercase\n",
    "- tokenize\n",
    "- keep only alphabetic tokens\n",
    "- remove stopwords (common function words like *the*, *and*)\n",
    "\n",
    "This keeps the lab simple while preserving enough information for meaningful embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "764b3b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in first document (first 50):\n",
      "['wondering', 'anyone', 'could', 'enlighten', 'car', 'saw', 'day', 'sports', 'car', 'looked', 'late', 'early', 'called', 'bricklin', 'doors', 'really', 'small', 'addition', 'front', 'bumper', 'separate', 'rest', 'body', 'know', 'anyone', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'production', 'car', 'made', 'history', 'whatever', 'info', 'funky', 'looking', 'car', 'please']\n"
     ]
    }
   ],
   "source": [
    "# Build stopword set once\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess(text: str):\n",
    "    \"\"\"Convert raw text into a list of clean tokens.\n",
    "\n",
    "    Steps:\n",
    "    1) Lowercase\n",
    "    2) Tokenize\n",
    "    3) Keep alphabetic tokens only (drop numbers/punctuation)\n",
    "    4) Remove stopwords\n",
    "\n",
    "    Returns:\n",
    "        List[str]: cleaned tokens\n",
    "    \"\"\"\n",
    "    # TODO: Implement the preprocessing steps\n",
    "    # 1. Lowercase and tokenize using word_tokenize\n",
    "    # 2. Filter to keep only alphabetic tokens that are not stopwords\n",
    "    \n",
    "    tokens = word_tokenize(text.lower())  # YOUR CODE HERE\n",
    "    tokens = [t for t in tokens if t.isalpha() and t not in stop_words]  # YOUR CODE HERE (filter step)\n",
    "    return tokens\n",
    "\n",
    "# Tokenize the full corpus\n",
    "corpus = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Quick sanity check\n",
    "print(\"Tokens in first document (first 50):\")\n",
    "print(corpus[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d62d47",
   "metadata": {},
   "source": [
    "---\n",
    "## Checkpoint 1 (Data + preprocessing)\n",
    "1. Why might we remove stopwords for this lab?\n",
    "2. Name one situation where removing stopwords could be a bad idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5278098",
   "metadata": {},
   "source": [
    "1. We remove stopwrods to reduce noise and focus learning on content bearing words.\n",
    "2. Removing them is a bad idea when function words carry meaning (eg sentiment/negation like \"not\", or authorship/stylistic signals)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbaba5a",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2 — Distributional semantics (concept)\n",
    "\n",
    "A central idea from modern NLP is:\n",
    "\n",
    "> **\"You shall know a word by the company it keeps.\"** (J. R. Firth)\n",
    "\n",
    "In practice:\n",
    "- a word's **context** = nearby words within a window\n",
    "- words that occur in similar contexts get similar vectors\n",
    "\n",
    "This is why embeddings can capture semantic similarity without hand-built resources like WordNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a14dd",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3 — Word2Vec (Skip-gram)\n",
    "\n",
    "### What Word2Vec does (high level)\n",
    "Word2Vec learns word vectors by solving a **prediction task**.\n",
    "\n",
    "In **Skip-gram**, the model learns to:\n",
    "- take a **center word** and predict surrounding **context words**\n",
    "\n",
    "Key hyperparameters:\n",
    "- `vector_size`: embedding dimension (typical 50 to 300)\n",
    "- `window`: context window size\n",
    "- `min_count`: ignore rare words\n",
    "- `sg=1`: Skip-gram (sg=0 would be CBOW)\n",
    "\n",
    "> Note: In practice, Word2Vec is usually trained with **negative sampling** for speed, rather than a full softmax over the entire vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f626c1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 18095\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train Word2Vec (Skip-gram)\n",
    "# Use: sentences=corpus, vector_size=100, window=5, min_count=5, workers=4, sg=1\n",
    "\n",
    "w2v = Word2Vec(\n",
    "    sentences=corpus,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "print(\"Vocabulary size:\", len(w2v.wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de56c077",
   "metadata": {},
   "source": [
    "### Inspect a learned vector\n",
    "\n",
    "The numbers themselves are not interpretable dimension-by-dimension.  \n",
    "Meaning comes from **relative position in the vector space**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6e8e245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.90926397,  1.159697  ,  0.66478485, -0.35344714,  0.00858668,\n",
       "       -0.9001314 ,  0.3617567 ,  1.390696  , -0.9557    , -0.7639389 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Inspect the first 10 values of the word vector for \"computer\"\n",
    "# Use w2v.wv[\"computer\"] to access the vector\n",
    "\n",
    "# YOUR CODE HERE\n",
    "w2v.wv[\"car\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468a6897",
   "metadata": {},
   "source": [
    "### Word2Vec vs Bag-of-Words vs N-grams\n",
    "\n",
    "| Aspect | Bag-of-Words | N-grams | Word2Vec |\n",
    "|--------|--------------|---------|----------|\n",
    "| **Representation** | Sparse vector (word counts) | Sparse vector (sequence counts) | Dense vector (learned embeddings) |\n",
    "| **Dimensionality** | Vocabulary size (10K–100K+) | Exponentially larger (V^n) | Fixed, small (50–300) |\n",
    "| **Word order** | ❌ Ignored | ✅ Captures local sequences | ❌ Ignored (but context matters during training) |\n",
    "| **Semantic similarity** | ❌ No — \"cat\" and \"dog\" are orthogonal | ❌ No | ✅ Yes — similar words have similar vectors |\n",
    "| **Handles rare/unseen words** | ❌ OOV problem | ❌ OOV problem | ❌ OOV problem (FastText helps) |\n",
    "| **Sparsity** | Very high | Even higher | None (dense) |\n",
    "| **Training required** | No (just counting) | No (just counting) | Yes (neural network) |\n",
    "\n",
    "**Key takeaways:**\n",
    "- **Bag-of-Words** treats documents as unordered collections of words. Simple and fast, but loses word order and has no notion of similarity.\n",
    "- **N-grams** capture local word sequences (bigrams, trigrams), preserving some order. However, they explode in size and remain sparse.\n",
    "- **Word2Vec** learns dense, low-dimensional vectors where **semantically similar words are close together**. This enables similarity search, analogies, and better generalization to unseen data.\n",
    "\n",
    "> **Why this matters:** Bag-of-Words and N-grams suffer from the **curse of dimensionality** and cannot generalize across synonyms. Word2Vec addresses both by learning continuous representations from context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1059abf",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4 — Similarity search (nearest neighbors)\n",
    "\n",
    "A common industry use of embeddings is **semantic similarity**.\n",
    "\n",
    "Example:\n",
    "- If a user searches for *\"motel\"*, we may want to retrieve documents about *\"hotel\"*.\n",
    "- With one-hot vectors, these are unrelated (orthogonal).\n",
    "- With embeddings, similar words often end up near each other in space.\n",
    "\n",
    "We typically measure similarity using **cosine similarity**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d64442c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'computer':\n",
      "network         : 0.945616\n",
      "systems         : 0.916866\n",
      "commercial      : 0.898698\n",
      "digital         : 0.895187\n",
      "products        : 0.893066\n",
      "project         : 0.888186\n",
      "voice           : 0.881723\n",
      "software        : 0.879878\n",
      "currently       : 0.873857\n",
      "computers       : 0.871531\n",
      "bbs             : 0.868684\n",
      "electronic      : 0.862725\n",
      "users           : 0.858830\n",
      "design          : 0.851476\n",
      "includes        : 0.850446\n",
      "technology      : 0.850007\n",
      "registration    : 0.848573\n",
      "engineering     : 0.848441\n",
      "service         : 0.844689\n",
      "development     : 0.843514\n",
      "access          : 0.843390\n",
      "additional      : 0.843186\n",
      "companies       : 0.841198\n",
      "capabilities    : 0.840354\n",
      "networks        : 0.838888\n",
      "export          : 0.838706\n",
      "remote          : 0.838093\n",
      "mainframe       : 0.836097\n",
      "equipment       : 0.834125\n",
      "management      : 0.833566\n"
     ]
    }
   ],
   "source": [
    "# TODO: Find most similar words to \"computer\"\n",
    "# Use w2v.wv.most_similar(target, topn=10)\n",
    "\n",
    "target = \"computer\"\n",
    "print(f\"Most similar words to '{target}':\")\n",
    "\n",
    "for word, score in w2v.wv.most_similar(target, topn=30):\n",
    "    print(f'{word:15s} : {score:3f}')\n",
    "\n",
    "\n",
    "# YOUR CODE HERE - iterate through the results and print each word and score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94743f2b",
   "metadata": {},
   "source": [
    "---\n",
    "## Checkpoint 2 (Interpretation)\n",
    "Look at the nearest neighbors you got for **computer**.\n",
    "1. Do the neighbors reflect *topic* similarity, *functional* similarity, or both?\n",
    "2. Pick 1 surprising neighbor and propose a reason it might appear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32195355",
   "metadata": {},
   "source": [
    "1. The nearest neighbors for computer usually reflect mostly topic similarity, sometimes mixed with functional similarity.\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa037657",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5 — Vector algebra (analogies)\n",
    "\n",
    "### Why this is in the notebook\n",
    "Vector algebra (analogies) demonstrates one of the most remarkable properties of word embeddings: **semantic relationships are encoded as geometric directions**. This section is included because:\n",
    "\n",
    "1. **Validates embedding quality** — If embeddings capture meaningful structure, analogies should work\n",
    "2. **Illustrates the \"linear substructure\" hypothesis** — Relationships like gender, tense, or country-capital are often parallel vectors\n",
    "3. **Common interview/exam topic** — The king–queen analogy is a classic NLP question\n",
    "4. **Foundation for downstream tasks** — Understanding vector arithmetic helps with transfer learning and feature engineering\n",
    "\n",
    "### How vector algebra works\n",
    "\n",
    "Embeddings often capture relationships as **directions** in vector space. The idea is:\n",
    "\n",
    "> If the relationship between **king** and **man** is similar to the relationship between **queen** and **woman**, then their difference vectors should be approximately equal.\n",
    "\n",
    "Mathematically:\n",
    "$$\\vec{king} - \\vec{man} \\approx \\vec{queen} - \\vec{woman}$$\n",
    "\n",
    "Rearranging:\n",
    "$$\\vec{king} - \\vec{man} + \\vec{woman} \\approx \\vec{queen}$$\n",
    "\n",
    "### Classic example\n",
    "\n",
    "\\[ \\text{king} - \\text{man} + \\text{woman} \\approx \\text{queen} \\]\n",
    "\n",
    "This works *sometimes* because the model learns consistent patterns across many contexts.\n",
    "\n",
    "### Other analogy types that embeddings can capture\n",
    "\n",
    "| Relationship | Example |\n",
    "|--------------|---------|\n",
    "| Verb tense | walk : walked :: swim : swam |\n",
    "| Country–capital | France : Paris :: Japan : Tokyo |\n",
    "| Comparative | big : bigger :: small : smaller |\n",
    "| Plural | cat : cats :: dog : dogs |\n",
    "\n",
    "### Important caveats\n",
    "\n",
    "- **Analogies are an intrinsic evaluation** — They test the embedding space itself, not real-world task performance\n",
    "- **Results are dataset-dependent** — A model trained on news articles may not capture analogies about cooking or medicine\n",
    "- **Not always reliable** — Even good embeddings can fail on specific analogies due to data biases or polysemy (words with multiple meanings)\n",
    "- **Sensitive to corpus size** — Small corpora may not provide enough context for consistent relationship patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84f7ff75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('savagely', 0.9696977138519287),\n",
       " ('slaughtered', 0.9618241786956787),\n",
       " ('fleeing', 0.9595695734024048),\n",
       " ('bears', 0.9588884711265564),\n",
       " ('eastern', 0.956122100353241),\n",
       " ('agdam', 0.9546986818313599),\n",
       " ('shostack', 0.9542818665504456),\n",
       " ('weaver', 0.9541596174240112),\n",
       " ('lenin', 0.9529090523719788),\n",
       " ('azerbadjan', 0.9518402814865112),\n",
       " ('anatolia', 0.951659619808197),\n",
       " ('village', 0.9512597322463989),\n",
       " ('served', 0.9503478407859802),\n",
       " ('lake', 0.9502660632133484),\n",
       " ('adam', 0.95011305809021),\n",
       " ('azeri', 0.9495853185653687),\n",
       " ('girls', 0.9495486617088318),\n",
       " ('joseph', 0.9495049118995667),\n",
       " ('retreat', 0.94905686378479),\n",
       " ('guberniia', 0.9485239386558533)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Perform analogy using vector arithmetic\n",
    "# Use w2v.wv.most_similar(positive=[...], negative=[...], topn=5)\n",
    "# Try: king - man + woman = ?\n",
    "\n",
    "# YOUR CODE HERE\n",
    "w2v.wv.most_similar(\n",
    "    positive=['king', 'woman'],\n",
    "    negative=['man'],\n",
    "    topn=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3d29a",
   "metadata": {},
   "source": [
    "### Why \"queen\" might not appear\n",
    "\n",
    "- **Training corpus matters** — Your model was trained on the 20 Newsgroups dataset, which is about tech, politics, religion, and sports. Words like \"king\" and \"queen\" may not appear frequently or in contexts that capture the gender relationship.\n",
    "\n",
    "- **Corpus size** — 20 Newsgroups has ~11,000 documents. The famous king-queen analogy was demonstrated on models trained on billions of words.\n",
    "\n",
    "- **Context diversity** — For the analogy to work, the model needs to see \"king\" and \"queen\" in parallel contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17338756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if \"queen\" is in the vocabulary\n",
    "\"queen\" in w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5f97b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity to 'queen': 0.7797\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate the cosine similarity between the result vector and \"queen\"\n",
    "# 1. Compute result_vec = w2v.wv[\"king\"] - w2v.wv[\"man\"] + w2v.wv[\"woman\"]\n",
    "# 2. Get queen_vec = w2v.wv[\"queen\"]\n",
    "# 3. Calculate cosine similarity using: np.dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "from numpy.linalg import norm\n",
    "\n",
    "result_vec = w2v.wv['king'] - w2v.wv['man'] + w2v.wv['woman']\n",
    "queen_vec = w2v.wv['queen']\n",
    "\n",
    "similarity = np.dot(result_vec, queen_vec) / (norm(result_vec) * norm(queen_vec))\n",
    "print(f\"Cosine similarity to 'queen': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdc4b6e",
   "metadata": {},
   "source": [
    "---\n",
    "## Checkpoint 3 (Why analogies are tricky)\n",
    "1. Why might analogy results be wrong even if the embeddings are \"good\"?\n",
    "2. Give one reason analogy evaluation might not correlate with task performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca41937f",
   "metadata": {},
   "source": [
    "1. Analogies can be wrong even with good embeddings because vector offsets don’t always represent clean relationships and results are sensitive to corpus bias/frequency.\n",
    "2. Analogy scores may not correlate with real tasks because downstream performance depends on domain, labels, and objectives (not just geometric neatness)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca84156",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6 — Visualizing embeddings (debugging skill)\n",
    "\n",
    "In practice, visualization helps you:\n",
    "- sanity-check whether embeddings capture structure\n",
    "- detect domain problems (too small corpus, noisy preprocessing)\n",
    "- communicate results to non-technical stakeholders\n",
    "\n",
    "We will use **PCA** to reduce vectors to 2D.\n",
    "\n",
    "> Important: A 2D projection can distort distances. Treat it as a visual aid, not a perfect representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "898b3b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Visualize word embeddings using PCA\n",
    "# 1. Define a list of words to visualize\n",
    "# 2. Filter to keep only words in vocabulary\n",
    "# 3. Get vectors for those words\n",
    "# 4. Use PCA to reduce to 2D\n",
    "# 5. Plot with labels\n",
    "\n",
    "words = [\n",
    "    \"computer\", \"software\", \"hardware\", \"internet\",\n",
    "    \"doctor\", \"nurse\", \"hospital\", \"medicine\",\n",
    "    \"government\", \"policy\", \"law\", \"rights\"\n",
    "]\n",
    "\n",
    "# Keep only words that exist in the vocabulary\n",
    "words = [w for w in words if w in w2v.wv]\n",
    "\n",
    "# TODO: Get vectors and apply PCA\n",
    "vectors = np.array([w2v.wv[w] for w in words])  # YOUR CODE HERE\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(vectors)  # YOUR CODE HERE\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(9, 6))\n",
    "for i, w in enumerate(words):\n",
    "    plt.scatter(coords[i, 0], coords[i, 1])\n",
    "    plt.text(coords[i, 0] + 0.02, coords[i, 1] + 0.02, w)\n",
    "\n",
    "plt.title(\"Word2Vec Embeddings Projected to 2D (PCA)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb9d895",
   "metadata": {},
   "source": [
    "---\n",
    "## Checkpoint 4 (Visualization reading)\n",
    "1. Which words are closest together in your plot?\n",
    "2. Do you see clusters (health vs tech vs politics)? If not, what might explain that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0de07d",
   "metadata": {},
   "source": [
    "1. In my plot, hospital, doctor, nurse and medicine are closet together, where are internet, computer, hardware and software are together, and law, government, right, policy are close together.\n",
    "2. I don't see the clusters between health, tech and politics because they don't share the similar context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b806f57",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7 — FastText (subword embeddings)\n",
    "\n",
    "### Why FastText exists\n",
    "Word2Vec learns a vector for each *word token*. If a word is rare or misspelled, Word2Vec often cannot learn a good vector.\n",
    "\n",
    "FastText improves this by representing a word as a bag of **character n-grams**.\n",
    "That means it can build vectors for:\n",
    "- rare words\n",
    "- morphological variants (plural, verb forms)\n",
    "- unseen words (depending on implementation)\n",
    "\n",
    "Industry relevance:\n",
    "- user-generated text (typos, slang)\n",
    "- domain text (technical words)\n",
    "- languages with rich morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3aed49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText vocabulary size: 18095\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train FastText on the same corpus\n",
    "# Use: sentences=corpus, vector_size=100, window=5, min_count=5, workers=4\n",
    "\n",
    "ft = FastText(\n",
    "    sentences=corpus,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "print(\"FastText vocabulary size:\", len(ft.wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4deba9",
   "metadata": {},
   "source": [
    "### Compare Word2Vec vs FastText behavior\n",
    "\n",
    "We compare neighbors for a related word form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc0fbf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText neighbors for: computers\n",
      "computes        : 0.972396\n",
      "compact         : 0.961642\n",
      "comics          : 0.961011\n",
      "compute         : 0.958045\n",
      "items           : 0.949269\n",
      "subsystems      : 0.945871\n",
      "competitors     : 0.944908\n",
      "compuadd        : 0.944640\n",
      "techniques      : 0.941423\n",
      "company         : 0.939628\n",
      "\n",
      "Word2Vec neighbors for: computers\n",
      "products        : 0.972636\n",
      "additional      : 0.971226\n",
      "bbs             : 0.964201\n",
      "ocr             : 0.962724\n",
      "currently       : 0.960367\n",
      "crypt           : 0.960062\n",
      "shareware       : 0.959636\n",
      "packages        : 0.959104\n",
      "turbocom        : 0.958172\n",
      "items           : 0.957744\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compare similarity results for \"computers\" between FastText and Word2Vec\n",
    "\n",
    "query = \"computers\"\n",
    "\n",
    "# # FastText neighbors\n",
    "print(\"FastText neighbors for:\", query)\n",
    "for word, score in ft.wv.most_similar(query, topn=10):\n",
    "    print(f'{word:15s} : {score:3f}')\n",
    "\n",
    "# Word2Vec neighbors (check if word exists first)\n",
    "if query in w2v.wv:\n",
    "    print(\"\\nWord2Vec neighbors for:\", query)\n",
    "    for word, score in w2v.wv.most_similar(query, topn=10):\n",
    "        print(f'{word:15s} : {score:3f}')\n",
    "    \n",
    "else:\n",
    "    print(\"\\nWord2Vec does not contain the token 'computers' in its vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0565d416",
   "metadata": {},
   "source": [
    "### Summary: Word2Vec vs FastText\n",
    "\n",
    "| Aspect | Word2Vec | FastText |\n",
    "|--------|----------|----------|\n",
    "| **Unit of learning** | Whole words | Words + character n-grams (subwords) |\n",
    "| **Vocabulary** | Fixed at training time | Can generate vectors for unseen words |\n",
    "| **OOV (out-of-vocabulary) handling** | ❌ Cannot handle — returns error | ✅ Builds vector from subword pieces |\n",
    "| **Morphological variants** | Treated as separate tokens (run ≠ running) | Related by shared subwords (run ≈ running) |\n",
    "| **Typos and misspellings** | ❌ No vector available | ✅ Still produces reasonable vector |\n",
    "| **Training speed** | Faster | Slower (more parameters) |\n",
    "| **Model size** | Smaller | Larger (stores subword vectors) |\n",
    "| **Memory usage** | Lower | Higher |\n",
    "\n",
    "### When to use Word2Vec\n",
    "\n",
    "✅ **Choose Word2Vec when:**\n",
    "- Your vocabulary is **stable and well-defined** (e.g., curated product names)\n",
    "- You need **faster training** and smaller models\n",
    "- Your corpus is **clean** with minimal typos\n",
    "- You're working with **English or morphologically simple languages**\n",
    "- Memory and storage are constrained\n",
    "\n",
    "### When to use FastText\n",
    "\n",
    "✅ **Choose FastText when:**\n",
    "- You expect **out-of-vocabulary words** at inference time\n",
    "- Working with **user-generated content** (social media, reviews, chat)\n",
    "- Your domain has **technical jargon** or rare terminology\n",
    "- Working with **morphologically rich languages** (German, Finnish, Turkish, Arabic)\n",
    "- You need to handle **typos, slang, or informal spelling**\n",
    "- New words/products/entities appear frequently\n",
    "\n",
    "### Real-world example\n",
    "\n",
    "| Scenario | Best Choice | Reason |\n",
    "|----------|-------------|--------|\n",
    "| Search engine for product catalog | Word2Vec | Products are known; vocabulary is controlled |\n",
    "| Twitter sentiment analysis | FastText | Typos, slang, hashtags are common |\n",
    "| Medical NLP with rare drug names | FastText | Drug names share prefixes/suffixes |\n",
    "| News article classification | Word2Vec | Clean, edited text |\n",
    "| Customer support chatbot | FastText | Users make typos |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e3ebf4",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8 — Practical mini-task: Build a tiny \"semantic search\" demo\n",
    "\n",
    "In industry, a common workflow is:\n",
    "1) choose an embedding model  \n",
    "2) represent text units as vectors  \n",
    "3) retrieve nearest neighbors to answer queries\n",
    "\n",
    "We will implement a simplified version:\n",
    "- take a query word\n",
    "- find its nearest neighbors\n",
    "- interpret results\n",
    "\n",
    "This is not full document search yet, but it is the core idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "198ac0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: motel\n",
      "  (word not in vocabulary)\n",
      "\n",
      "Query: hotel\n",
      "  ventura         0.992\n",
      "  paris           0.991\n",
      "  barbara         0.991\n",
      "  pa              0.990\n",
      "  hill            0.990\n",
      "  princeton       0.989\n",
      "  pennsylvania    0.989\n",
      "  forbes          0.988\n",
      "\n",
      "Query: space\n",
      "  nasa            0.885\n",
      "  shuttle         0.880\n",
      "  launch          0.861\n",
      "  station         0.832\n",
      "  commercial      0.789\n",
      "  flight          0.788\n",
      "  research        0.783\n",
      "  center          0.781\n",
      "\n",
      "Query: religion\n",
      "  religious       0.984\n",
      "  islam           0.981\n",
      "  christian       0.978\n",
      "  christians      0.975\n",
      "  religions       0.973\n",
      "  christianity    0.972\n",
      "  belief          0.971\n",
      "  evidence        0.971\n",
      "\n",
      "Query: graphics\n",
      "  programming     0.981\n",
      "  unix            0.970\n",
      "  ibm             0.962\n",
      "  postscript      0.961\n",
      "  workstations    0.961\n",
      "  mpeg            0.961\n",
      "  manual          0.961\n",
      "  borland         0.960\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement a semantic_neighbors function and test it with queries\n",
    "\n",
    "def semantic_neighbors(model, word: str, topn: int = 10):\n",
    "    \"\"\"Return nearest neighbors for a word, with a friendly error message.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Check if word is in model.wv, if not return None\n",
    "    # Otherwise return model.wv.most_similar(word, topn=topn)\n",
    "    if word not in model.wv:\n",
    "        return None\n",
    "    return model.wv.most_similar(word, topn=topn)\n",
    "    \n",
    "    pass\n",
    "\n",
    "queries = [\"motel\", \"hotel\", \"space\", \"religion\", \"graphics\"]\n",
    "\n",
    "for q in queries:\n",
    "    result = semantic_neighbors(w2v, q, topn=8)\n",
    "    print(\"\\nQuery:\", q)\n",
    "    if result is None:\n",
    "        print(\"  (word not in vocabulary)\")\n",
    "    else:\n",
    "        for w, s in result:\n",
    "            print(f\"  {w:15s} {s:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d1f3c",
   "metadata": {},
   "source": [
    "---\n",
    "## Checkpoint 5 (Industry thinking)\n",
    "Pick one query from the output above:\n",
    "1. Would these neighbors help a search engine user?\n",
    "2. What could go wrong if we deploy this directly in production?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb03a35",
   "metadata": {},
   "source": [
    "1. Neighbors can help search by expanding queries with semantically related terms.\n",
    "2. Deploying directly can go wrong via bias amplification, irrelevant expansions (false positives), domain drift, and problematic/unsafe associations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db1c0b0",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 9 — Where does GloVe fit? (concept-only)\n",
    "\n",
    "You learned in lecture that we can also build a **co-occurrence matrix** \\(X\\) and try to compress it.\n",
    "\n",
    "Two major perspectives:\n",
    "1. **Predictive models** (Word2Vec): learn by predicting context  \n",
    "2. **Count-based global models** (GloVe): learn from aggregated co-occurrence statistics\n",
    "\n",
    "GloVe aims to encode meaning using **ratios of co-occurrence probabilities**, and often shows strong linear structure (useful for analogies).\n",
    "\n",
    "We do not train GloVe from scratch here because:\n",
    "- it requires building and storing large co-occurrence statistics\n",
    "- training is heavier than Word2Vec/FastText for an in-class lab\n",
    "\n",
    "However, you should understand the core difference:\n",
    "- Word2Vec: local prediction objective\n",
    "- GloVe: global co-occurrence objective\n",
    "\n",
    "**You will see GloVe again** when using pretrained embeddings in later weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cb33a2",
   "metadata": {},
   "source": [
    "---\n",
    "## Final Reflection (Submit)\n",
    "\n",
    "Write short answers (3 to 6 sentences each):\n",
    "\n",
    "1. How do embeddings solve the sparsity and \"no similarity\" issues of one-hot vectors?\n",
    "2. What is a realistic industry task where word embeddings are useful?\n",
    "3. When would you choose FastText over Word2Vec?\n",
    "4. What is one risk or limitation of word embeddings that a practitioner should watch for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6a47d1",
   "metadata": {},
   "source": [
    "---\n",
    "## Assignment\n",
    "\n",
    "- Change `window` (2, 10) and compare neighbors for the same query word.\n",
    "- Increase `vector_size` (50 vs 200) and compare results.\n",
    "- Try CBOW: set `sg=0` and compare results with Skip-gram.\n",
    "- Add bigrams using `gensim.models.Phrases` before training and observe changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a6e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "def semantic_neighbors(model, word: str, topn: int = 10):\n",
    "    \"\"\"Return nearest neighbors for a word, or None if OOV.\"\"\"\n",
    "    if word not in model.wv:\n",
    "        return None\n",
    "    return model.wv.most_similar(word, topn=topn)\n",
    "\n",
    "def neighbors_df(model, query, topn=10, label=\"model\"):\n",
    "    \"\"\"Return a neat DataFrame of neighbors.\"\"\"\n",
    "    result = semantic_neighbors(model, query, topn=topn)\n",
    "    if result is None:\n",
    "        return pd.DataFrame({\"model\":[label], \"query\":[query], \"neighbor\":[\"(OOV)\"], \"score\":[None]})\n",
    "    return pd.DataFrame({\n",
    "        \"model\": [label]*len(result),\n",
    "        \"query\": [query]*len(result),\n",
    "        \"neighbor\": [w for w,_ in result],\n",
    "        \"score\": [s for _,s in result]\n",
    "    })\n",
    "\n",
    "def train_w2v(sentences, vector_size=100, window=5, sg=1, min_count=5, workers=4, seed=42):\n",
    "    \"\"\"Train Word2Vec with specified params.\"\"\"\n",
    "    model = Word2Vec(\n",
    "        sentences=sentences,\n",
    "        vector_size=vector_size,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "        workers=workers,\n",
    "        sg=sg,\n",
    "        seed=seed\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63078268",
   "metadata": {},
   "source": [
    "\n",
    "### neighbors_df(model, query, topn, label):\n",
    "This converts the neighbor results into a clean DataFrame with columns: model name, query, neighbor, score.\n",
    "\n",
    "If the word is not in vocab, it returns a one-row table saying (OOV) instead of failing.\n",
    "\n",
    "The label helps you compare multiple models side-by-side.\n",
    "\n",
    "### train_w2v(sentences, vector_size, window, sg, ...)\n",
    "This is a reusable trainer that builds a Word2Vec model using parameters you specify.\n",
    "\n",
    "vector_size controls the embedding dimension (how much “space” the model has to store meaning).\n",
    "\n",
    "window controls how far the model looks around a word to learn context.\n",
    "\n",
    "sg=1 means Skip-gram, sg=0 means CBOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db06a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_word = \"religion\"\n",
    "topn = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bc6433",
   "metadata": {},
   "source": [
    "You set one query word (like \"religion\") and reuse it for all experiments.\n",
    "\n",
    "This makes your comparisons fair because only one parameter changes at a time.\n",
    "\n",
    "topn is the number of neighbors you want to show (like top 10 similar words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "878cfc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>query</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip-gram window=2</td>\n",
       "      <td>religion</td>\n",
       "      <td>religions</td>\n",
       "      <td>0.923043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skip-gram window=2</td>\n",
       "      <td>religion</td>\n",
       "      <td>doctrine</td>\n",
       "      <td>0.920998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skip-gram window=2</td>\n",
       "      <td>religion</td>\n",
       "      <td>christianity</td>\n",
       "      <td>0.918216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skip-gram window=2</td>\n",
       "      <td>religion</td>\n",
       "      <td>doctrines</td>\n",
       "      <td>0.918077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip-gram window=2</td>\n",
       "      <td>religion</td>\n",
       "      <td>mormon</td>\n",
       "      <td>0.917247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Skip-gram window=2</td>\n",
       "      <td>religion</td>\n",
       "      <td>teachings</td>\n",
       "      <td>0.914945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Skip-gram window=2</td>\n",
       "      <td>religion</td>\n",
       "      <td>beings</td>\n",
       "      <td>0.911539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Skip-gram window=2</td>\n",
       "      <td>religion</td>\n",
       "      <td>teaching</td>\n",
       "      <td>0.910580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Skip-gram window=2</td>\n",
       "      <td>religion</td>\n",
       "      <td>scholars</td>\n",
       "      <td>0.908908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Skip-gram window=2</td>\n",
       "      <td>religion</td>\n",
       "      <td>believers</td>\n",
       "      <td>0.907296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Skip-gram window=10</td>\n",
       "      <td>religion</td>\n",
       "      <td>religions</td>\n",
       "      <td>0.811676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Skip-gram window=10</td>\n",
       "      <td>religion</td>\n",
       "      <td>religious</td>\n",
       "      <td>0.793890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Skip-gram window=10</td>\n",
       "      <td>religion</td>\n",
       "      <td>fundamentalist</td>\n",
       "      <td>0.783914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Skip-gram window=10</td>\n",
       "      <td>religion</td>\n",
       "      <td>christianity</td>\n",
       "      <td>0.783799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Skip-gram window=10</td>\n",
       "      <td>religion</td>\n",
       "      <td>caste</td>\n",
       "      <td>0.773772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Skip-gram window=10</td>\n",
       "      <td>religion</td>\n",
       "      <td>prejudice</td>\n",
       "      <td>0.773353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Skip-gram window=10</td>\n",
       "      <td>religion</td>\n",
       "      <td>perverse</td>\n",
       "      <td>0.772047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Skip-gram window=10</td>\n",
       "      <td>religion</td>\n",
       "      <td>embrace</td>\n",
       "      <td>0.771520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Skip-gram window=10</td>\n",
       "      <td>religion</td>\n",
       "      <td>gender</td>\n",
       "      <td>0.770864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Skip-gram window=10</td>\n",
       "      <td>religion</td>\n",
       "      <td>thinker</td>\n",
       "      <td>0.770734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model     query        neighbor     score\n",
       "0    Skip-gram window=2  religion       religions  0.923043\n",
       "1    Skip-gram window=2  religion        doctrine  0.920998\n",
       "2    Skip-gram window=2  religion    christianity  0.918216\n",
       "3    Skip-gram window=2  religion       doctrines  0.918077\n",
       "4    Skip-gram window=2  religion          mormon  0.917247\n",
       "5    Skip-gram window=2  religion       teachings  0.914945\n",
       "6    Skip-gram window=2  religion          beings  0.911539\n",
       "7    Skip-gram window=2  religion        teaching  0.910580\n",
       "8    Skip-gram window=2  religion        scholars  0.908908\n",
       "9    Skip-gram window=2  religion       believers  0.907296\n",
       "10  Skip-gram window=10  religion       religions  0.811676\n",
       "11  Skip-gram window=10  religion       religious  0.793890\n",
       "12  Skip-gram window=10  religion  fundamentalist  0.783914\n",
       "13  Skip-gram window=10  religion    christianity  0.783799\n",
       "14  Skip-gram window=10  religion           caste  0.773772\n",
       "15  Skip-gram window=10  religion       prejudice  0.773353\n",
       "16  Skip-gram window=10  religion        perverse  0.772047\n",
       "17  Skip-gram window=10  religion         embrace  0.771520\n",
       "18  Skip-gram window=10  religion          gender  0.770864\n",
       "19  Skip-gram window=10  religion         thinker  0.770734"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_w2 = train_w2v(corpus, vector_size=100, window=2, sg=1)\n",
    "w2v_w10 = train_w2v(corpus, vector_size=100, window=10, sg=1)\n",
    "\n",
    "df = pd.concat([\n",
    "    neighbors_df(w2v_w2, query_word, topn=topn, label=\"Skip-gram window=2\"),\n",
    "    neighbors_df(w2v_w10, query_word, topn=topn, label=\"Skip-gram window=10\"),\n",
    "], ignore_index=True)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf6bea",
   "metadata": {},
   "source": [
    "You train two models with the same settings except window size.\n",
    "\n",
    "window=2 learns from very local context → often tighter, phrase-like associations.\n",
    "\n",
    "window=10 learns from wider context → often more topic/semantic associations.\n",
    "\n",
    "Then you combine both results into one table to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60a5af68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>query</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip-gram vec=50</td>\n",
       "      <td>religion</td>\n",
       "      <td>religious</td>\n",
       "      <td>0.873017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skip-gram vec=50</td>\n",
       "      <td>religion</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.867348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skip-gram vec=50</td>\n",
       "      <td>religion</td>\n",
       "      <td>judaism</td>\n",
       "      <td>0.862252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skip-gram vec=50</td>\n",
       "      <td>religion</td>\n",
       "      <td>religions</td>\n",
       "      <td>0.859832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip-gram vec=50</td>\n",
       "      <td>religion</td>\n",
       "      <td>viewpoint</td>\n",
       "      <td>0.859271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Skip-gram vec=50</td>\n",
       "      <td>religion</td>\n",
       "      <td>intellectual</td>\n",
       "      <td>0.857289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Skip-gram vec=50</td>\n",
       "      <td>religion</td>\n",
       "      <td>doctrines</td>\n",
       "      <td>0.855128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Skip-gram vec=50</td>\n",
       "      <td>religion</td>\n",
       "      <td>beings</td>\n",
       "      <td>0.854976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Skip-gram vec=50</td>\n",
       "      <td>religion</td>\n",
       "      <td>christianity</td>\n",
       "      <td>0.853984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Skip-gram vec=50</td>\n",
       "      <td>religion</td>\n",
       "      <td>mormons</td>\n",
       "      <td>0.851520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Skip-gram vec=200</td>\n",
       "      <td>religion</td>\n",
       "      <td>religions</td>\n",
       "      <td>0.886080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Skip-gram vec=200</td>\n",
       "      <td>religion</td>\n",
       "      <td>christianity</td>\n",
       "      <td>0.861040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Skip-gram vec=200</td>\n",
       "      <td>religion</td>\n",
       "      <td>believers</td>\n",
       "      <td>0.847504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Skip-gram vec=200</td>\n",
       "      <td>religion</td>\n",
       "      <td>judaism</td>\n",
       "      <td>0.846377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Skip-gram vec=200</td>\n",
       "      <td>religion</td>\n",
       "      <td>intellectual</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Skip-gram vec=200</td>\n",
       "      <td>religion</td>\n",
       "      <td>doctrines</td>\n",
       "      <td>0.845129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Skip-gram vec=200</td>\n",
       "      <td>religion</td>\n",
       "      <td>homosexuality</td>\n",
       "      <td>0.840534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Skip-gram vec=200</td>\n",
       "      <td>religion</td>\n",
       "      <td>traditions</td>\n",
       "      <td>0.839971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Skip-gram vec=200</td>\n",
       "      <td>religion</td>\n",
       "      <td>islam</td>\n",
       "      <td>0.838857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Skip-gram vec=200</td>\n",
       "      <td>religion</td>\n",
       "      <td>religious</td>\n",
       "      <td>0.828525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model     query       neighbor     score\n",
       "0    Skip-gram vec=50  religion      religious  0.873017\n",
       "1    Skip-gram vec=50  religion      christian  0.867348\n",
       "2    Skip-gram vec=50  religion        judaism  0.862252\n",
       "3    Skip-gram vec=50  religion      religions  0.859832\n",
       "4    Skip-gram vec=50  religion      viewpoint  0.859271\n",
       "5    Skip-gram vec=50  religion   intellectual  0.857289\n",
       "6    Skip-gram vec=50  religion      doctrines  0.855128\n",
       "7    Skip-gram vec=50  religion         beings  0.854976\n",
       "8    Skip-gram vec=50  religion   christianity  0.853984\n",
       "9    Skip-gram vec=50  religion        mormons  0.851520\n",
       "10  Skip-gram vec=200  religion      religions  0.886080\n",
       "11  Skip-gram vec=200  religion   christianity  0.861040\n",
       "12  Skip-gram vec=200  religion      believers  0.847504\n",
       "13  Skip-gram vec=200  religion        judaism  0.846377\n",
       "14  Skip-gram vec=200  religion   intellectual  0.846154\n",
       "15  Skip-gram vec=200  religion      doctrines  0.845129\n",
       "16  Skip-gram vec=200  religion  homosexuality  0.840534\n",
       "17  Skip-gram vec=200  religion     traditions  0.839971\n",
       "18  Skip-gram vec=200  religion          islam  0.838857\n",
       "19  Skip-gram vec=200  religion      religious  0.828525"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_v50 = train_w2v(corpus, vector_size=50, window=5, sg=1)\n",
    "w2v_v200 = train_w2v(corpus, vector_size=200, window=5, sg=1)\n",
    "\n",
    "df = pd.concat([\n",
    "    neighbors_df(w2v_v50, query_word, topn=topn, label=\"Skip-gram vec=50\"),\n",
    "    neighbors_df(w2v_v200, query_word, topn=topn, label=\"Skip-gram vec=200\"),\n",
    "], ignore_index=True)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af367926",
   "metadata": {},
   "source": [
    "You train two models with the same settings except vector dimension.\n",
    "\n",
    "Smaller vectors (50) can be faster but may lose detail → neighbors can look noisier.\n",
    "\n",
    "Larger vectors (200) can capture richer meaning → but needs enough data to avoid overfitting.\n",
    "\n",
    "The output table shows how the neighborhood changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8b5a70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>query</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBOW (sg=0)</td>\n",
       "      <td>religion</td>\n",
       "      <td>religious</td>\n",
       "      <td>0.984856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBOW (sg=0)</td>\n",
       "      <td>religion</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.981997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBOW (sg=0)</td>\n",
       "      <td>religion</td>\n",
       "      <td>evidence</td>\n",
       "      <td>0.977756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBOW (sg=0)</td>\n",
       "      <td>religion</td>\n",
       "      <td>religions</td>\n",
       "      <td>0.974748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBOW (sg=0)</td>\n",
       "      <td>religion</td>\n",
       "      <td>islam</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CBOW (sg=0)</td>\n",
       "      <td>religion</td>\n",
       "      <td>christianity</td>\n",
       "      <td>0.974584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CBOW (sg=0)</td>\n",
       "      <td>religion</td>\n",
       "      <td>christians</td>\n",
       "      <td>0.974409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CBOW (sg=0)</td>\n",
       "      <td>religion</td>\n",
       "      <td>revelation</td>\n",
       "      <td>0.971767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CBOW (sg=0)</td>\n",
       "      <td>religion</td>\n",
       "      <td>existence</td>\n",
       "      <td>0.969434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CBOW (sg=0)</td>\n",
       "      <td>religion</td>\n",
       "      <td>beliefs</td>\n",
       "      <td>0.968612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Skip-gram (sg=1)</td>\n",
       "      <td>religion</td>\n",
       "      <td>religions</td>\n",
       "      <td>0.881827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Skip-gram (sg=1)</td>\n",
       "      <td>religion</td>\n",
       "      <td>christianity</td>\n",
       "      <td>0.863903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Skip-gram (sg=1)</td>\n",
       "      <td>religion</td>\n",
       "      <td>judaism</td>\n",
       "      <td>0.855580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Skip-gram (sg=1)</td>\n",
       "      <td>religion</td>\n",
       "      <td>religious</td>\n",
       "      <td>0.850450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Skip-gram (sg=1)</td>\n",
       "      <td>religion</td>\n",
       "      <td>intellectual</td>\n",
       "      <td>0.848759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Skip-gram (sg=1)</td>\n",
       "      <td>religion</td>\n",
       "      <td>doctrines</td>\n",
       "      <td>0.843459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Skip-gram (sg=1)</td>\n",
       "      <td>religion</td>\n",
       "      <td>denominations</td>\n",
       "      <td>0.841271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Skip-gram (sg=1)</td>\n",
       "      <td>religion</td>\n",
       "      <td>islam</td>\n",
       "      <td>0.838586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Skip-gram (sg=1)</td>\n",
       "      <td>religion</td>\n",
       "      <td>sexuality</td>\n",
       "      <td>0.838491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Skip-gram (sg=1)</td>\n",
       "      <td>religion</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.837768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model     query       neighbor     score\n",
       "0        CBOW (sg=0)  religion      religious  0.984856\n",
       "1        CBOW (sg=0)  religion      christian  0.981997\n",
       "2        CBOW (sg=0)  religion       evidence  0.977756\n",
       "3        CBOW (sg=0)  religion      religions  0.974748\n",
       "4        CBOW (sg=0)  religion          islam  0.974648\n",
       "5        CBOW (sg=0)  religion   christianity  0.974584\n",
       "6        CBOW (sg=0)  religion     christians  0.974409\n",
       "7        CBOW (sg=0)  religion     revelation  0.971767\n",
       "8        CBOW (sg=0)  religion      existence  0.969434\n",
       "9        CBOW (sg=0)  religion        beliefs  0.968612\n",
       "10  Skip-gram (sg=1)  religion      religions  0.881827\n",
       "11  Skip-gram (sg=1)  religion   christianity  0.863903\n",
       "12  Skip-gram (sg=1)  religion        judaism  0.855580\n",
       "13  Skip-gram (sg=1)  religion      religious  0.850450\n",
       "14  Skip-gram (sg=1)  religion   intellectual  0.848759\n",
       "15  Skip-gram (sg=1)  religion      doctrines  0.843459\n",
       "16  Skip-gram (sg=1)  religion  denominations  0.841271\n",
       "17  Skip-gram (sg=1)  religion          islam  0.838586\n",
       "18  Skip-gram (sg=1)  religion      sexuality  0.838491\n",
       "19  Skip-gram (sg=1)  religion      christian  0.837768"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_cbow = train_w2v(corpus, vector_size=100, window=5, sg=0)\n",
    "w2v_sg   = train_w2v(corpus, vector_size=100, window=5, sg=1)\n",
    "\n",
    "df = pd.concat([\n",
    "    neighbors_df(w2v_cbow, query_word, topn=topn, label=\"CBOW (sg=0)\"),\n",
    "    neighbors_df(w2v_sg, query_word, topn=topn, label=\"Skip-gram (sg=1)\"),\n",
    "], ignore_index=True)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e77feb",
   "metadata": {},
   "source": [
    "CBOW is usually smoother and works well for frequent words.\n",
    "\n",
    "Skip-gram often captures better relationships for rarer words (but may be slower).\n",
    "\n",
    "You train one model in CBOW mode and one in Skip-gram mode.\n",
    "\n",
    "CBOW predicts the word from its context → often stable for frequent words.\n",
    "\n",
    "Skip-gram predicts context from the word → often better for rare words and relationships.\n",
    "\n",
    "The table helps you see which gives more meaningful neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ef751f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>query</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (no bigrams)</td>\n",
       "      <td>religion</td>\n",
       "      <td>religions</td>\n",
       "      <td>0.872665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline (no bigrams)</td>\n",
       "      <td>religion</td>\n",
       "      <td>judaism</td>\n",
       "      <td>0.855256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline (no bigrams)</td>\n",
       "      <td>religion</td>\n",
       "      <td>intellectual</td>\n",
       "      <td>0.848207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline (no bigrams)</td>\n",
       "      <td>religion</td>\n",
       "      <td>religious</td>\n",
       "      <td>0.842927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline (no bigrams)</td>\n",
       "      <td>religion</td>\n",
       "      <td>christianity</td>\n",
       "      <td>0.836171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline (no bigrams)</td>\n",
       "      <td>religion</td>\n",
       "      <td>believers</td>\n",
       "      <td>0.830357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baseline (no bigrams)</td>\n",
       "      <td>religion</td>\n",
       "      <td>doctrines</td>\n",
       "      <td>0.830113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baseline (no bigrams)</td>\n",
       "      <td>religion</td>\n",
       "      <td>beliefs</td>\n",
       "      <td>0.829603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baseline (no bigrams)</td>\n",
       "      <td>religion</td>\n",
       "      <td>islam</td>\n",
       "      <td>0.828659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baseline (no bigrams)</td>\n",
       "      <td>religion</td>\n",
       "      <td>racist</td>\n",
       "      <td>0.825363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>With bigrams</td>\n",
       "      <td>religion</td>\n",
       "      <td>islam</td>\n",
       "      <td>0.928565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>With bigrams</td>\n",
       "      <td>religion</td>\n",
       "      <td>religions</td>\n",
       "      <td>0.927153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>With bigrams</td>\n",
       "      <td>religion</td>\n",
       "      <td>doctrines</td>\n",
       "      <td>0.923111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>With bigrams</td>\n",
       "      <td>religion</td>\n",
       "      <td>teachings</td>\n",
       "      <td>0.911798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>With bigrams</td>\n",
       "      <td>religion</td>\n",
       "      <td>gods</td>\n",
       "      <td>0.910545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>With bigrams</td>\n",
       "      <td>religion</td>\n",
       "      <td>judaism</td>\n",
       "      <td>0.908734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>With bigrams</td>\n",
       "      <td>religion</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.907237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>With bigrams</td>\n",
       "      <td>religion</td>\n",
       "      <td>doctrine</td>\n",
       "      <td>0.906080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>With bigrams</td>\n",
       "      <td>religion</td>\n",
       "      <td>theology</td>\n",
       "      <td>0.905448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>With bigrams</td>\n",
       "      <td>religion</td>\n",
       "      <td>rejecting</td>\n",
       "      <td>0.905364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model     query      neighbor     score\n",
       "0   Baseline (no bigrams)  religion     religions  0.872665\n",
       "1   Baseline (no bigrams)  religion       judaism  0.855256\n",
       "2   Baseline (no bigrams)  religion  intellectual  0.848207\n",
       "3   Baseline (no bigrams)  religion     religious  0.842927\n",
       "4   Baseline (no bigrams)  religion  christianity  0.836171\n",
       "5   Baseline (no bigrams)  religion     believers  0.830357\n",
       "6   Baseline (no bigrams)  religion     doctrines  0.830113\n",
       "7   Baseline (no bigrams)  religion       beliefs  0.829603\n",
       "8   Baseline (no bigrams)  religion         islam  0.828659\n",
       "9   Baseline (no bigrams)  religion        racist  0.825363\n",
       "10           With bigrams  religion         islam  0.928565\n",
       "11           With bigrams  religion     religions  0.927153\n",
       "12           With bigrams  religion     doctrines  0.923111\n",
       "13           With bigrams  religion     teachings  0.911798\n",
       "14           With bigrams  religion          gods  0.910545\n",
       "15           With bigrams  religion       judaism  0.908734\n",
       "16           With bigrams  religion     christian  0.907237\n",
       "17           With bigrams  religion      doctrine  0.906080\n",
       "18           With bigrams  religion      theology  0.905448\n",
       "19           With bigrams  religion     rejecting  0.905364"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learn bigram phrases from the corpus\n",
    "phrases = Phrases(corpus, min_count=5, threshold=10)\n",
    "bigram = Phraser(phrases)\n",
    "\n",
    "# Transform corpus into bigram-aware corpus\n",
    "corpus_bi = [bigram[sent] for sent in corpus]\n",
    "\n",
    "# Train baseline vs bigram model\n",
    "w2v_base = train_w2v(corpus, vector_size=100, window=5, sg=1)\n",
    "w2v_bi   = train_w2v(corpus_bi, vector_size=100, window=5, sg=1)\n",
    "\n",
    "df = pd.concat([\n",
    "    neighbors_df(w2v_base, query_word, topn=topn, label=\"Baseline (no bigrams)\"),\n",
    "    neighbors_df(w2v_bi, query_word, topn=topn, label=\"With bigrams\"),\n",
    "], ignore_index=True)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e26e3e",
   "metadata": {},
   "source": [
    "With bigrams, the model treats common two-word expressions as single concepts, which often improves meaning for phrases.\n",
    "\n",
    "You first learn common two-word phrases from your corpus (Phrases).\n",
    "\n",
    "Then you transform the corpus so those phrases become single tokens like new_york.\n",
    "\n",
    "You train a model on the bigram corpus and compare it to the baseline model.\n",
    "\n",
    "This improves embeddings for multi-word concepts that should act like one meaning unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abaa6d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['max_max',\n",
       " 'x_x',\n",
       " 'r_g',\n",
       " 'g_r',\n",
       " 'would_like',\n",
       " 'q_q',\n",
       " 'n_n',\n",
       " 'united_states',\n",
       " 'new_york',\n",
       " 'db_db',\n",
       " 'anyone_know',\n",
       " 'thanks_advance',\n",
       " 'last_year',\n",
       " 'p_p',\n",
       " 'something_like',\n",
       " 'many_people',\n",
       " 'law_enforcement',\n",
       " 'clipper_chip',\n",
       " 'even_though',\n",
       " 'los_angeles',\n",
       " 'years_ago',\n",
       " 'make_sure',\n",
       " 'looks_like',\n",
       " 'power_play',\n",
       " 'w_w',\n",
       " 'gun_control',\n",
       " 'max_q',\n",
       " 'q_p',\n",
       " 'r_r',\n",
       " 'hard_drive']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See examples of learned phrases (may show as \"x_y\")\n",
    "examples = [w for w in w2v_bi.wv.index_to_key if \"_\" in w][:30]\n",
    "examples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aig230-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
